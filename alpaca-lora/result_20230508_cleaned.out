/home/tricorder/yang/anaconda3/envs/llama_alpaca_lora/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: /home/tricorder/yang/anaconda3/envs/llama_alpaca_lora did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...
  warn(msg)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes

 and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
bin /home/tricorder/yang/anaconda3/envs/llama_alpaca_lora/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so
CUDA SETUP: CUDA runtime path found: /usr/local/cuda-11.7/lib64/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.0
CUDA SETUP: Detected CUDA version 117
CUDA SETUP: Loading binary /home/tricorder/yang/anaconda3/envs/llama_alpaca_lora/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...
Training Alpaca-LoRA model with params:
base_model: /home/tricorder/test/gxc/decapoda-research/llama-7b-hf
data_path: ../data/alpaca_data_cleaned_archive.json
output_dir: ../lora_alpaca_output_free/cleaned/
batch_size: 1024
micro_batch_size: 4
num_epochs: 5
learning_rate: 2e-05
cutoff_len: 512
val_set_size: 2000
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q_proj', 'v_proj']
train_on_inputs:  
add_eos_token:  
group_by_length: True
wandb_project: llama_test_project
wandb_run_name:  
wandb_watch: gradients
wandb_log_model:  
resume_from_checkpoint:  
prompt template: alpaca

Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/33 [00:00<00:12,  2.55it/s]Loading checkpoint shards:   6%|▌         | 2/33 [00:00<00:11,  2.63it/s]Loading checkpoint shards:   9%|▉         | 3/33 [00:01<00:11,  2.61it/s]Loading checkpoint shards:  12%|█▏        | 4/33 [00:01<00:10,  2.64it/s]Loading checkpoint shards:  15%|█▌        | 5/33 [00:01<00:10,  2.65it/s]Loading checkpoint shards:  18%|█▊        | 6/33 [00:02<00:10,  2.64it/s]Loading checkpoint shards:  21%|██        | 7/33 [00:02<00:09,  2.64it/s]Loading checkpoint shards:  24%|██▍       | 8/33 [00:03<00:09,  2.66it/s]Loading checkpoint shards:  27%|██▋       | 9/33 [00:03<00:09,  2.64it/s]Loading checkpoint shards:  30%|███       | 10/33 [00:03<00:08,  2.65it/s]Loading checkpoint shards:  33%|███▎      | 11/33 [00:04<00:08,  2.65it/s]Loading checkpoint shards:  36%|███▋      | 12/33 [00:04<00:07,  2.64it/s]Loading checkpoint shards:  39%|███▉      | 13/33 [00:04<00:07,  2.53it/s]Loading checkpoint shards:  42%|████▏     | 14/33 [00:05<00:07,  2.58it/s]Loading checkpoint shards:  45%|████▌     | 15/33 [00:05<00:07,  2.54it/s]Loading checkpoint shards:  48%|████▊     | 16/33 [00:06<00:06,  2.58it/s]Loading checkpoint shards:  52%|█████▏    | 17/33 [00:06<00:06,  2.59it/s]Loading checkpoint shards:  55%|█████▍    | 18/33 [00:06<00:05,  2.62it/s]Loading checkpoint shards:  58%|█████▊    | 19/33 [00:07<00:05,  2.62it/s]Loading checkpoint shards:  61%|██████    | 20/33 [00:07<00:04,  2.61it/s]Loading checkpoint shards:  64%|██████▎   | 21/33 [00:08<00:04,  2.61it/s]Loading checkpoint shards:  67%|██████▋   | 22/33 [00:08<00:04,  2.61it/s]Loading checkpoint shards:  70%|██████▉   | 23/33 [00:08<00:03,  2.61it/s]Loading checkpoint shards:  73%|███████▎  | 24/33 [00:09<00:03,  2.63it/s]Loading checkpoint shards:  76%|███████▌  | 25/33 [00:09<00:03,  2.64it/s]Loading checkpoint shards:  79%|███████▉  | 26/33 [00:09<00:02,  2.65it/s]Loading checkpoint shards:  82%|████████▏ | 27/33 [00:10<00:02,  2.66it/s]Loading checkpoint shards:  85%|████████▍ | 28/33 [00:10<00:01,  2.66it/s]Loading checkpoint shards:  88%|████████▊ | 29/33 [00:11<00:01,  2.68it/s]Loading checkpoint shards:  91%|█████████ | 30/33 [00:11<00:01,  2.68it/s]Loading checkpoint shards:  94%|█████████▍| 31/33 [00:11<00:00,  2.67it/s]Loading checkpoint shards:  97%|█████████▋| 32/33 [00:12<00:00,  2.67it/s]Loading checkpoint shards: 100%|██████████| 33/33 [00:12<00:00,  2.52it/s]Loading checkpoint shards: 100%|██████████| 33/33 [00:12<00:00,  2.62it/s]
The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. 
The class this function is called from is 'LlamaTokenizer'.
Downloading and preparing dataset json/default to /home/tricorder/yang/datasets/json/default-3531275c72a953af/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...
Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 7681.88it/s]
Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 1199.40it/s]
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 51759 examples [00:00, 215451.88 examples/s]                                                                    Dataset json downloaded and prepared to /home/tricorder/yang/datasets/json/default-3531275c72a953af/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 544.86it/s]
Checkpoint  /adapter_model.bin not found
trainable params: 4194304 || all params: 6742609920 || trainable%: 0.06220594176090199
Map:   0%|          | 0/49759 [00:00<?, ? examples/s]Map:   0%|          | 131/49759 [00:00<00:38, 1286.25 examples/s]Map:   1%|          | 266/49759 [00:00<00:37, 1320.94 examples/s]Map:   1%|          | 414/49759 [00:00<00:35, 1391.26 examples/s]Map:   1%|          | 617/49759 [00:00<00:35, 1369.14 examples/s]Map:   2%|▏         | 760/49759 [00:00<00:35, 1385.01 examples/s]Map:   2%|▏         | 966/49759 [00:00<00:35, 1378.89 examples/s]Map:   2%|▏         | 1149/49759 [00:00<00:37, 1308.02 examples/s]Map:   3%|▎         | 1290/49759 [00:00<00:36, 1330.84 examples/s]Map:   3%|▎         | 1429/49759 [00:01<00:35, 1344.69 examples/s]Map:   3%|▎         | 1574/49759 [00:01<00:35, 1368.55 examples/s]Map:   3%|▎         | 1716/49759 [00:01<00:34, 1379.89 examples/s]Map:   4%|▎         | 1861/49759 [00:01<00:34, 1397.14 examples/s]Map:   4%|▍         | 2028/49759 [00:01<00:37, 1288.30 examples/s]Map:   4%|▍         | 2181/49759 [00:01<00:35, 1350.77 examples/s]Map:   5%|▍         | 2322/49759 [00:01<00:34, 1364.58 examples/s]Map:   5%|▍         | 2466/49759 [00:01<00:34, 1384.26 examples/s]Map:   5%|▌         | 2610/49759 [00:01<00:33, 1398.91 examples/s]Map:   6%|▌         | 2804/49759 [00:02<00:34, 1353.27 examples/s]Map:   6%|▌         | 2947/49759 [00:02<00:34, 1373.00 examples/s]Map:   6%|▋         | 3138/49759 [00:02<00:36, 1269.26 examples/s]Map:   7%|▋         | 3284/49759 [00:02<00:35, 1315.70 examples/s]Map:   7%|▋         | 3430/49759 [00:02<00:34, 1349.49 examples/s]Map:   7%|▋         | 3637/49759 [00:02<00:34, 1356.22 examples/s]Map:   8%|▊         | 3780/49759 [00:02<00:33, 1373.71 examples/s]Map:   8%|▊         | 3928/49759 [00:02<00:32, 1399.68 examples/s]Map:   8%|▊         | 4071/49759 [00:03<00:35, 1300.01 examples/s]Map:   8%|▊         | 4214/49759 [00:03<00:34, 1332.86 examples/s]Map:   9%|▉         | 4361/49759 [00:03<00:33, 1369.63 examples/s]Map:   9%|▉         | 4508/49759 [00:03<00:32, 1394.11 examples/s]Map:   9%|▉         | 4651/49759 [00:03<00:32, 1402.97 examples/s]Map:  10%|▉         | 4861/49759 [00:03<00:32, 1399.23 examples/s]Map:  10%|█         | 5025/49759 [00:03<00:34, 1288.56 examples/s]Map:  10%|█         | 5163/49759 [00:03<00:34, 1307.33 examples/s]Map:  11%|█         | 5302/49759 [00:03<00:33, 1327.05 examples/s]Map:  11%|█         | 5441/49759 [00:04<00:33, 1341.70 examples/s]Map:  11%|█▏        | 5642/49759 [00:04<00:32, 1338.46 examples/s]Map:  12%|█▏        | 5783/49759 [00:04<00:32, 1355.52 examples/s]Map:  12%|█▏        | 5929/49759 [00:04<00:31, 1380.14 examples/s]Map:  12%|█▏        | 6132/49759 [00:04<00:34, 1266.88 examples/s]Map:  13%|█▎        | 6272/49759 [00:04<00:33, 1295.74 examples/s]Map:  13%|█▎        | 6413/49759 [00:04<00:32, 1322.29 examples/s]Map:  13%|█▎        | 6559/49759 [00:04<00:31, 1357.20 examples/s]Map:  14%|█▎        | 6760/49759 [00:05<00:31, 1348.12 examples/s]Map:  14%|█▍        | 6955/49759 [00:05<00:32, 1330.21 examples/s]Map:  14%|█▍        | 7140/49759 [00:05<00:34, 1248.30 examples/s]Map:  15%|█▍        | 7284/49759 [00:05<00:32, 1289.47 examples/s]Map:  15%|█▍        | 7430/49759 [00:05<00:31, 1330.48 examples/s]Map:  15%|█▌        | 7627/49759 [00:05<00:31, 1319.53 examples/s]Map:  16%|█▌        | 7774/49759 [00:05<00:31, 1353.21 examples/s]Map:  16%|█▌        | 7915/49759 [00:05<00:30, 1366.94 examples/s]Map:  16%|█▌        | 8076/49759 [00:06<00:33, 1258.33 examples/s]Map:  17%|█▋        | 8218/49759 [00:06<00:31, 1298.76 examples/s]Map:  17%|█▋        | 8364/49759 [00:06<00:30, 1339.81 examples/s]Map:  17%|█▋        | 8507/49759 [00:06<00:30, 1361.71 examples/s]Map:  18%|█▊        | 8715/49759 [00:06<00:30, 1366.63 examples/s]Map:  18%|█▊        | 8923/49759 [00:06<00:29, 1368.40 examples/s]Map:  18%|█▊        | 9087/49759 [00:06<00:31, 1273.28 examples/s]Map:  19%|█▊        | 9221/49759 [00:06<00:31, 1287.55 examples/s]Map:  19%|█▉        | 9362/49759 [00:06<00:30, 1316.05 examples/s]Map:  19%|█▉        | 9511/49759 [00:07<00:29, 1358.66 examples/s]Map:  19%|█▉        | 9649/49759 [00:07<00:29, 1363.42 examples/s]Map:  20%|█▉        | 9794/49759 [00:07<00:28, 1385.60 examples/s]Map:  20%|██        | 10000/49759 [00:07<00:30, 1295.97 examples/s]Map:  20%|██        | 10140/49759 [00:07<00:30, 1319.75 examples/s]Map:  21%|██        | 10343/49759 [00:07<00:29, 1325.91 examples/s]Map:  21%|██        | 10486/49759 [00:07<00:29, 1348.84 examples/s]Map:  21%|██▏       | 10636/49759 [00:07<00:28, 1384.59 examples/s]Map:  22%|██▏       | 10839/49759 [00:08<00:28, 1365.04 examples/s]Map:  22%|██▏       | 10981/49759 [00:08<00:28, 1373.51 examples/s]Map:  22%|██▏       | 11148/49759 [00:08<00:30, 1279.48 examples/s]Map:  23%|██▎       | 11289/49759 [00:08<00:29, 1309.67 examples/s]Map:  23%|██▎       | 11432/49759 [00:08<00:28, 1338.61 examples/s]Map:  23%|██▎       | 11576/49759 [00:08<00:28, 1362.24 examples/s]Map:  24%|██▎       | 11716/49759 [00:08<00:27, 1367.83 examples/s]Map:  24%|██▍       | 11857/49759 [00:08<00:27, 1378.53 examples/s]Map:  24%|██▍       | 12000/49759 [00:08<00:29, 1274.99 examples/s]Map:  24%|██▍       | 12151/49759 [00:09<00:28, 1336.00 examples/s]Map:  25%|██▍       | 12350/49759 [00:09<00:28, 1328.44 examples/s]Map:  25%|██▌       | 12551/49759 [00:09<00:28, 1327.93 examples/s]Map:  26%|██▌       | 12702/49759 [00:09<00:27, 1366.69 examples/s]Map:  26%|██▌       | 12850/49759 [00:09<00:26, 1394.44 examples/s]Map:  26%|██▌       | 13008/49759 [00:09<00:28, 1268.66 examples/s]Map:  26%|██▋       | 13143/49759 [00:09<00:28, 1283.69 examples/s]Map:  27%|██▋       | 13288/49759 [00:09<00:27, 1325.28 examples/s]Map:  27%|██▋       | 13425/49759 [00:10<00:27, 1333.81 examples/s]Map:  27%|██▋       | 13566/49759 [00:10<00:26, 1350.89 examples/s]Map:  28%|██▊       | 13715/49759 [00:10<00:25, 1388.26 examples/s]Map:  28%|██▊       | 13865/49759 [00:10<00:25, 1417.45 examples/s]Map:  28%|██▊       | 14071/49759 [00:10<00:27, 1295.07 examples/s]Map:  29%|██▊       | 14212/49759 [00:10<00:26, 1321.08 examples/s]Map:  29%|██▉       | 14355/49759 [00:10<00:26, 1348.27 examples/s]Map:  29%|██▉       | 14497/49759 [00:10<00:25, 1364.31 examples/s]Map:  30%|██▉       | 14707/49759 [00:10<00:25, 1371.77 examples/s]Map:  30%|██▉       | 14855/49759 [00:11<00:24, 1397.82 examples/s]Map:  30%|███       | 15000/49759 [00:11<00:26, 1300.74 examples/s]Map:  30%|███       | 15145/49759 [00:11<00:25, 1336.74 examples/s]Map:  31%|███       | 15292/49759 [00:11<00:25, 1372.46 examples/s]Map:  31%|███       | 15492/49759 [00:11<00:25, 1352.65 examples/s]Map:  31%|███▏      | 15640/49759 [00:11<00:24, 1381.20 examples/s]Map:  32%|███▏      | 15783/49759 [00:11<00:32, 1042.53 examples/s]Map:  32%|███▏      | 15922/49759 [00:11<00:30, 1118.32 examples/s]Map:  32%|███▏      | 16086/49759 [00:12<00:30, 1108.26 examples/s]Map:  33%|███▎      | 16228/49759 [00:12<00:28, 1181.47 examples/s]Map:  33%|███▎      | 16371/49759 [00:12<00:26, 1241.21 examples/s]Map:  33%|███▎      | 16514/49759 [00:12<00:25, 1288.04 examples/s]Map:  33%|███▎      | 16655/49759 [00:12<00:25, 1319.70 examples/s]Map:  34%|███▍      | 16802/49759 [00:12<00:24, 1358.97 examples/s]Map:  34%|███▍      | 16946/49759 [00:12<00:23, 1380.46 examples/s]Map:  34%|███▍      | 17145/49759 [00:12<00:24, 1306.44 examples/s]Map:  35%|███▍      | 17287/49759 [00:13<00:24, 1333.31 examples/s]Map:  35%|███▌      | 17430/49759 [00:13<00:23, 1358.10 examples/s]Map:  35%|███▌      | 17641/49759 [00:13<00:23, 1371.14 examples/s]Map:  36%|███▌      | 17844/49759 [00:13<00:23, 1361.91 examples/s]Map:  36%|███▌      | 17988/49759 [00:13<00:23, 1377.99 examples/s]Map:  36%|███▋      | 18149/49759 [00:13<00:24, 1270.40 examples/s]Map:  37%|███▋      | 18284/49759 [00:13<00:24, 1288.39 examples/s]Map:  37%|███▋      | 18423/49759 [00:13<00:23, 1312.62 examples/s]Map:  37%|███▋      | 18559/49759 [00:13<00:23, 1323.55 examples/s]Map:  38%|███▊      | 18707/49759 [00:14<00:22, 1364.71 examples/s]Map:  38%|███▊      | 18911/49759 [00:14<00:22, 1359.59 examples/s]Map:  38%|███▊      | 19082/49759 [00:14<00:23, 1280.70 examples/s]Map:  39%|███▊      | 19221/49759 [00:14<00:23, 1304.70 examples/s]Map:  39%|███▉      | 19368/49759 [00:14<00:22, 1344.05 examples/s]Map:  39%|███▉      | 19512/49759 [00:14<00:22, 1368.05 examples/s]Map:  40%|███▉      | 19660/49759 [00:14<00:21, 1394.83 examples/s]Map:  40%|███▉      | 19803/49759 [00:14<00:21, 1403.02 examples/s]Map:  40%|████      | 20000/49759 [00:15<00:22, 1305.80 examples/s]Map:  40%|████      | 20144/49759 [00:15<00:22, 1337.99 examples/s]Map:  41%|████      | 20287/49759 [00:15<00:21, 1358.90 examples/s]Map:  41%|████      | 20433/49759 [00:15<00:21, 1383.79 examples/s]Map:  41%|████▏     | 20647/49759 [00:15<00:20, 1397.53 examples/s]Map:  42%|████▏     | 20793/49759 [00:15<00:20, 1411.26 examples/s]Map:  42%|████▏     | 20940/49759 [00:15<00:20, 1423.39 examples/s]Map:  42%|████▏     | 21135/49759 [00:15<00:22, 1293.95 examples/s]Map:  43%|████▎     | 21275/49759 [00:15<00:21, 1317.12 examples/s]Map:  43%|████▎     | 21421/49759 [00:16<00:20, 1352.65 examples/s]Map:  43%|████▎     | 21570/49759 [00:16<00:20, 1385.97 examples/s]Map:  44%|████▎     | 21711/49759 [00:16<00:20, 1383.28 examples/s]Map:  44%|████▍     | 21859/49759 [00:16<00:19, 1406.98 examples/s]Map:  44%|████▍     | 22073/49759 [00:16<00:21, 1316.54 examples/s]Map:  45%|████▍     | 22216/49759 [00:16<00:20, 1341.00 examples/s]Map:  45%|████▍     | 22358/49759 [00:16<00:20, 1356.96 examples/s]Map:  45%|████▌     | 22508/49759 [00:16<00:19, 1392.29 examples/s]Map:  46%|████▌     | 22714/49759 [00:17<00:19, 1383.39 examples/s]Map:  46%|████▌     | 22926/49759 [00:17<00:19, 1388.30 examples/s]Map:  46%|████▋     | 23072/49759 [00:17<00:20, 1306.24 examples/s]Map:  47%|████▋     | 23221/49759 [00:17<00:19, 1343.48 examples/s]Map:  47%|████▋     | 23361/49759 [00:17<00:19, 1357.79 examples/s]Map:  47%|████▋     | 23505/49759 [00:17<00:19, 1376.89 examples/s]Map:  48%|████▊     | 23655/49759 [00:17<00:18, 1410.00 examples/s]Map:  48%|████▊     | 23870/49759 [00:17<00:18, 1412.31 examples/s]Map:  48%|████▊     | 24074/49759 [00:18<00:19, 1328.00 examples/s]Map:  49%|████▊     | 24215/49759 [00:18<00:18, 1346.17 examples/s]Map:  49%|████▉     | 24358/49759 [00:18<00:18, 1365.56 examples/s]Map:  49%|████▉     | 24565/49759 [00:18<00:18, 1365.39 examples/s]Map:  50%|████▉     | 24706/49759 [00:18<00:18, 1374.28 examples/s]Map:  50%|████▉     | 24847/49759 [00:18<00:18, 1380.40 examples/s]Map:  50%|█████     | 25000/49759 [00:18<00:19, 1247.35 examples/s]Map:  51%|█████     | 25144/49759 [00:18<00:19, 1293.48 examples/s]Map:  51%|█████     | 25279/49759 [00:18<00:18, 1306.39 examples/s]Map:  51%|█████     | 25425/49759 [00:19<00:18, 1344.71 examples/s]Map:  52%|█████▏    | 25632/49759 [00:19<00:17, 1355.85 examples/s]Map:  52%|█████▏    | 25771/49759 [00:19<00:17, 1363.73 examples/s]Map:  52%|█████▏    | 25911/49759 [00:19<00:17, 1371.95 examples/s]Map:  52%|█████▏    | 26071/49759 [00:19<00:18, 1254.82 examples/s]Map:  53%|█████▎    | 26214/49759 [00:19<00:18, 1294.80 examples/s]Map:  53%|█████▎    | 26350/49759 [00:19<00:17, 1311.63 examples/s]Map:  53%|█████▎    | 26485/49759 [00:19<00:17, 1320.08 examples/s]Map:  54%|█████▎    | 26632/49759 [00:19<00:17, 1359.30 examples/s]Map:  54%|█████▍    | 26775/49759 [00:20<00:16, 1377.24 examples/s]Map:  54%|█████▍    | 26915/49759 [00:20<00:16, 1379.69 examples/s]Map:  54%|█████▍    | 27084/49759 [00:20<00:17, 1279.94 examples/s]Map:  55%|█████▍    | 27225/49759 [00:20<00:17, 1310.42 examples/s]Map:  55%|█████▍    | 27360/49759 [00:20<00:16, 1320.04 examples/s]Map:  55%|█████▌    | 27514/49759 [00:20<00:16, 1381.00 examples/s]Map:  56%|█████▌    | 27660/49759 [00:20<00:15, 1401.43 examples/s]Map:  56%|█████▌    | 27806/49759 [00:20<00:15, 1412.20 examples/s]Map:  56%|█████▌    | 27950/49759 [00:20<00:15, 1419.70 examples/s]Map:  57%|█████▋    | 28148/49759 [00:21<00:16, 1323.89 examples/s]Map:  57%|█████▋    | 28285/49759 [00:21<00:16, 1334.50 examples/s]Map:  57%|█████▋    | 28431/49759 [00:21<00:15, 1365.46 examples/s]Map:  57%|█████▋    | 28574/49759 [00:21<00:15, 1379.02 examples/s]Map:  58%|█████▊    | 28722/49759 [00:21<00:14, 1403.43 examples/s]Map:  58%|█████▊    | 28932/49759 [00:21<00:14, 1398.86 examples/s]Map:  59%|█████▊    | 29148/49759 [00:21<00:15, 1314.44 examples/s]Map:  59%|█████▉    | 29292/49759 [00:21<00:15, 1339.82 examples/s]Map:  59%|█████▉    | 29435/49759 [00:21<00:14, 1360.30 examples/s]Map:  60%|█████▉    | 29642/49759 [00:22<00:14, 1364.88 examples/s]Map:  60%|█████▉    | 29790/49759 [00:22<00:14, 1390.61 examples/s]Map:  60%|██████    | 29934/49759 [00:22<00:14, 1401.53 examples/s]Map:  61%|██████    | 30141/49759 [00:22<00:15, 1302.11 examples/s]Map:  61%|██████    | 30280/49759 [00:22<00:14, 1322.13 examples/s]Map:  61%|██████    | 30418/49759 [00:22<00:14, 1334.70 examples/s]Map:  62%|██████▏   | 30626/49759 [00:22<00:14, 1350.64 examples/s]Map:  62%|██████▏   | 30767/49759 [00:22<00:13, 1360.29 examples/s]Map:  62%|██████▏   | 30979/49759 [00:23<00:13, 1373.43 examples/s]Map:  63%|██████▎   | 31145/49759 [00:23<00:14, 1282.87 examples/s]Map:  63%|██████▎   | 31279/49759 [00:23<00:14, 1293.02 examples/s]Map:  63%|██████▎   | 31422/49759 [00:23<00:13, 1323.65 examples/s]Map:  63%|██████▎   | 31563/49759 [00:23<00:13, 1345.04 examples/s]Map:  64%|██████▍   | 31768/49759 [00:23<00:13, 1352.20 examples/s]Map:  64%|██████▍   | 31908/49759 [00:23<00:13, 1360.37 examples/s]Map:  64%|██████▍   | 32072/49759 [00:23<00:13, 1264.49 examples/s]Map:  65%|██████▍   | 32209/49759 [00:24<00:13, 1288.07 examples/s]Map:  65%|██████▌   | 32345/49759 [00:24<00:13, 1303.99 examples/s]Map:  65%|██████▌   | 32489/49759 [00:24<00:12, 1338.66 examples/s]Map:  66%|██████▌   | 32695/49759 [00:24<00:12, 1348.78 examples/s]Map:  66%|██████▌   | 32836/49759 [00:24<00:12, 1363.93 examples/s]Map:  66%|██████▋   | 32975/49759 [00:24<00:12, 1369.80 examples/s]Map:  67%|██████▋   | 33147/49759 [00:24<00:13, 1276.67 examples/s]Map:  67%|██████▋   | 33289/49759 [00:24<00:12, 1311.55 examples/s]Map:  67%|██████▋   | 33431/49759 [00:24<00:12, 1338.91 examples/s]Map:  67%|██████▋   | 33572/49759 [00:25<00:11, 1355.80 examples/s]Map:  68%|██████▊   | 33715/49759 [00:25<00:11, 1373.27 examples/s]Map:  68%|██████▊   | 33860/49759 [00:25<00:11, 1394.29 examples/s]Map:  68%|██████▊   | 34020/49759 [00:25<00:12, 1266.23 examples/s]Map:  69%|██████▊   | 34165/49759 [00:25<00:11, 1311.81 examples/s]Map:  69%|██████▉   | 34304/49759 [00:25<00:11, 1327.75 examples/s]Map:  69%|██████▉   | 34446/49759 [00:25<00:11, 1350.24 examples/s]Map:  70%|██████▉   | 34583/49759 [00:25<00:11, 1354.09 examples/s]Map:  70%|██████▉   | 34725/49759 [00:25<00:10, 1372.15 examples/s]Map:  70%|███████   | 34875/49759 [00:26<00:10, 1407.92 examples/s]Map:  70%|███████   | 35067/49759 [00:26<00:11, 1293.48 examples/s]Map:  71%|███████   | 35206/49759 [00:26<00:11, 1315.55 examples/s]Map:  71%|███████   | 35351/49759 [00:26<00:10, 1349.45 examples/s]Map:  71%|███████▏  | 35569/49759 [00:26<00:10, 1384.57 examples/s]Map:  72%|███████▏  | 35780/49759 [00:26<00:10, 1390.01 examples/s]Map:  72%|███████▏  | 35921/49759 [00:26<00:09, 1392.93 examples/s]Map:  72%|███████▏  | 36075/49759 [00:26<00:10, 1265.35 examples/s]Map:  73%|███████▎  | 36218/49759 [00:27<00:10, 1303.57 examples/s]Map:  73%|███████▎  | 36367/49759 [00:27<00:09, 1344.45 examples/s]Map:  73%|███████▎  | 36510/49759 [00:27<00:09, 1363.92 examples/s]Map:  74%|███████▎  | 36661/49759 [00:27<00:09, 1401.48 examples/s]Map:  74%|███████▍  | 36805/49759 [00:27<00:09, 1409.28 examples/s]Map:  74%|███████▍  | 36956/49759 [00:27<00:08, 1435.87 examples/s]Map:  75%|███████▍  | 37140/49759 [00:27<00:09, 1305.51 examples/s]Map:  75%|███████▌  | 37353/49759 [00:27<00:09, 1341.42 examples/s]Map:  75%|███████▌  | 37499/49759 [00:27<00:08, 1368.86 examples/s]Map:  76%|███████▌  | 37643/49759 [00:28<00:08, 1382.64 examples/s]Map:  76%|███████▌  | 37790/49759 [00:28<00:08, 1403.00 examples/s]Map:  76%|███████▌  | 37933/49759 [00:28<00:08, 1408.62 examples/s]Map:  77%|███████▋  | 38146/49759 [00:28<00:08, 1309.66 examples/s]Map:  77%|███████▋  | 38344/49759 [00:28<00:08, 1311.40 examples/s]Map:  77%|███████▋  | 38488/49759 [00:28<00:08, 1340.68 examples/s]Map:  78%|███████▊  | 38629/49759 [00:28<00:08, 1355.99 examples/s]Map:  78%|███████▊  | 38777/49759 [00:28<00:07, 1387.84 examples/s]Map:  78%|███████▊  | 38921/49759 [00:29<00:07, 1397.98 examples/s]Map:  79%|███████▊  | 39092/49759 [00:29<00:08, 1295.38 examples/s]Map:  79%|███████▉  | 39232/49759 [00:29<00:07, 1319.43 examples/s]Map:  79%|███████▉  | 39380/49759 [00:29<00:07, 1361.55 examples/s]Map:  79%|███████▉  | 39521/49759 [00:29<00:07, 1372.21 examples/s]Map:  80%|███████▉  | 39660/49759 [00:29<00:07, 1373.23 examples/s]Map:  80%|███████▉  | 39802/49759 [00:29<00:07, 1383.02 examples/s]Map:  80%|████████  | 40000/49759 [00:29<00:07, 1275.41 examples/s]Map:  81%|████████  | 40137/49759 [00:29<00:07, 1297.56 examples/s]Map:  81%|████████  | 40285/49759 [00:30<00:07, 1343.53 examples/s]Map:  81%|████████  | 40429/49759 [00:30<00:06, 1366.68 examples/s]Map:  82%|████████▏ | 40639/49759 [00:30<00:06, 1375.86 examples/s]Map:  82%|████████▏ | 40845/49759 [00:30<00:06, 1370.24 examples/s]Map:  82%|████████▏ | 40992/49759 [00:30<00:06, 1392.77 examples/s]Map:  83%|████████▎ | 41157/49759 [00:30<00:06, 1287.71 examples/s]Map:  83%|████████▎ | 41302/49759 [00:30<00:06, 1325.61 examples/s]Map:  83%|████████▎ | 41446/49759 [00:30<00:06, 1350.74 examples/s]Map:  84%|████████▎ | 41587/49759 [00:31<00:05, 1364.02 examples/s]Map:  84%|████████▍ | 41727/49759 [00:31<00:05, 1370.07 examples/s]Map:  84%|████████▍ | 41872/49759 [00:31<00:05, 1386.36 examples/s]Map:  85%|████████▍ | 42069/49759 [00:31<00:06, 1279.15 examples/s]Map:  85%|████████▍ | 42213/49759 [00:31<00:05, 1316.87 examples/s]Map:  85%|████████▌ | 42356/49759 [00:31<00:05, 1346.14 examples/s]Map:  85%|████████▌ | 42494/49759 [00:31<00:05, 1354.99 examples/s]Map:  86%|████████▌ | 42640/49759 [00:31<00:05, 1378.47 examples/s]Map:  86%|████████▌ | 42853/49759 [00:31<00:04, 1390.47 examples/s]Map:  86%|████████▋ | 43000/49759 [00:32<00:05, 1304.73 examples/s]Map:  87%|████████▋ | 43142/49759 [00:32<00:04, 1332.56 examples/s]Map:  87%|████████▋ | 43282/49759 [00:32<00:04, 1347.91 examples/s]Map:  87%|████████▋ | 43491/49759 [00:32<00:04, 1361.23 examples/s]Map:  88%|████████▊ | 43692/49759 [00:32<00:04, 1351.13 examples/s]Map:  88%|████████▊ | 43834/49759 [00:32<00:04, 1366.18 examples/s]Map:  88%|████████▊ | 43980/49759 [00:32<00:04, 1388.35 examples/s]Map:  89%|████████▊ | 44149/49759 [00:32<00:04, 1291.84 examples/s]Map:  89%|████████▉ | 44287/49759 [00:33<00:04, 1311.81 examples/s]Map:  89%|████████▉ | 44426/49759 [00:33<00:04, 1330.07 examples/s]Map:  90%|████████▉ | 44571/49759 [00:33<00:03, 1358.73 examples/s]Map:  90%|████████▉ | 44718/49759 [00:33<00:03, 1387.98 examples/s]Map:  90%|█████████ | 44859/49759 [00:33<00:03, 1391.65 examples/s]Map:  90%|█████████ | 45018/49759 [00:33<00:03, 1262.67 examples/s]Map:  91%|█████████ | 45155/49759 [00:33<00:03, 1289.36 examples/s]Map:  91%|█████████ | 45301/49759 [00:33<00:03, 1334.86 examples/s]Map:  91%|█████████▏| 45440/49759 [00:33<00:03, 1345.10 examples/s]Map:  92%|█████████▏| 45582/49759 [00:34<00:03, 1364.54 examples/s]Map:  92%|█████████▏| 45785/49759 [00:34<00:02, 1356.63 examples/s]Map:  92%|█████████▏| 45923/49759 [00:34<00:02, 1360.32 examples/s]Map:  93%|█████████▎| 46082/49759 [00:34<00:02, 1247.04 examples/s]Map:  93%|█████████▎| 46230/49759 [00:34<00:02, 1304.70 examples/s]Map:  93%|█████████▎| 46369/49759 [00:34<00:02, 1325.02 examples/s]Map:  93%|█████████▎| 46504/49759 [00:34<00:02, 1328.07 examples/s]Map:  94%|█████████▍| 46651/49759 [00:34<00:02, 1365.95 examples/s]Map:  94%|█████████▍| 46795/49759 [00:34<00:02, 1382.78 examples/s]Map:  94%|█████████▍| 46937/49759 [00:35<00:02, 1391.83 examples/s]Map:  95%|█████████▍| 47141/49759 [00:35<00:02, 1296.07 examples/s]Map:  95%|█████████▌| 47283/49759 [00:35<00:01, 1325.38 examples/s]Map:  95%|█████████▌| 47429/49759 [00:35<00:01, 1359.39 examples/s]Map:  96%|█████████▌| 47573/49759 [00:35<00:01, 1377.45 examples/s]Map:  96%|█████████▌| 47782/49759 [00:35<00:01, 1382.83 examples/s]Map:  96%|█████████▋| 47994/49759 [00:35<00:01, 1391.55 examples/s]Map:  97%|█████████▋| 48172/49759 [00:35<00:01, 1320.55 examples/s]Map:  97%|█████████▋| 48307/49759 [00:36<00:01, 1325.54 examples/s]Map:  97%|█████████▋| 48447/49759 [00:36<00:00, 1339.87 examples/s]Map:  98%|█████████▊| 48587/49759 [00:36<00:00, 1352.12 examples/s]Map:  98%|█████████▊| 48732/49759 [00:36<00:00, 1373.83 examples/s]Map:  98%|█████████▊| 48875/49759 [00:36<00:00, 1388.44 examples/s]Map:  99%|█████████▊| 49069/49759 [00:36<00:00, 1297.81 examples/s]Map:  99%|█████████▉| 49218/49759 [00:36<00:00, 1342.93 examples/s]Map:  99%|█████████▉| 49429/49759 [00:36<00:00, 1361.07 examples/s]Map: 100%|█████████▉| 49638/49759 [00:37<00:00, 1368.06 examples/s]                                                                   Map:   0%|          | 0/2000 [00:00<?, ? examples/s]Map:   7%|▋         | 135/2000 [00:00<00:01, 1340.50 examples/s]Map:  14%|█▍        | 278/2000 [00:00<00:01, 1390.90 examples/s]Map:  21%|██        | 421/2000 [00:00<00:01, 1404.95 examples/s]Map:  32%|███▏      | 633/2000 [00:00<00:00, 1402.90 examples/s]Map:  39%|███▉      | 775/2000 [00:00<00:00, 1405.69 examples/s]Map:  49%|████▉     | 983/2000 [00:00<00:00, 1390.56 examples/s]Map:  57%|█████▋    | 1149/2000 [00:00<00:00, 1281.20 examples/s]Map:  64%|██████▍   | 1288/2000 [00:00<00:00, 1303.90 examples/s]Map:  72%|███████▏  | 1430/2000 [00:01<00:00, 1332.06 examples/s]Map:  82%|████████▏ | 1633/2000 [00:01<00:00, 1337.50 examples/s]Map:  89%|████████▉ | 1775/2000 [00:01<00:00, 1357.50 examples/s]Map:  96%|█████████▌| 1922/2000 [00:01<00:00, 1385.87 examples/s]                                                                 wandb: Currently logged in as: gaoxiaoce0428. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.15.2
wandb: Run data is saved locally in /home/tricorder/test/gxc/alpaca_lora_env/alpaca-lora/wandb/run-20230508_022333-xce58c9m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run  
wandb: ⭐️ View project at https://wandb.ai/gaoxiaoce0428/llama_test_project
wandb: 🚀 View run at https://wandb.ai/gaoxiaoce0428/llama_test_project/runs/xce58c9m
  0%|          | 0/240 [00:00<?, ?it/s]/home/tricorder/yang/anaconda3/envs/llama_alpaca_lora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  0%|          | 1/240 [10:49<43:08:52, 649.93s/it]  1%|          | 2/240 [19:48<38:37:17, 584.19s/it]  1%|▏         | 3/240 [28:02<35:44:42, 542.97s/it]  2%|▏         | 4/240 [35:44<33:30:23, 511.12s/it]  2%|▏         | 5/240 [43:14<31:55:32, 489.08s/it]  2%|▎         | 6/240 [50:23<30:27:52, 468.69s/it]  3%|▎         | 7/240 [57:11<29:03:41, 449.02s/it]  3%|▎         | 8/240 [1:04:48<29:05:00, 451.30s/it]  4%|▍         | 9/240 [1:12:24<29:04:07, 453.02s/it]  4%|▍         | 10/240 [1:19:30<28:24:09, 444.56s/it]                                                        4%|▍         | 10/240 [1:19:30<28:24:09, 444.56s/it]  5%|▍         | 11/240 [1:26:13<27:27:51, 431.75s/it]  5%|▌         | 12/240 [1:32:38<26:26:27, 417.49s/it]  5%|▌         | 13/240 [1:43:38<30:58:08, 491.14s/it]  6%|▌         | 14/240 [1:52:40<31:47:33, 506.43s/it]  6%|▋         | 15/240 [2:01:01<31:33:32, 504.94s/it]  7%|▋         | 16/240 [2:08:46<30:39:36, 492.75s/it]  7%|▋         | 17/240 [2:16:12<29:39:10, 478.70s/it]  8%|▊         | 18/240 [2:23:15<28:28:59, 461.89s/it]  8%|▊         | 19/240 [2:29:59<27:17:44, 444.63s/it]  8%|▊         | 20/240 [2:37:32<27:18:59, 447.00s/it]                                                        8%|▊         | 20/240 [2:37:32<27:18:59, 447.00s/it]  9%|▉         | 21/240 [2:45:06<27:19:51, 449.28s/it]  9%|▉         | 22/240 [2:52:18<26:53:19, 444.04s/it] 10%|▉         | 23/240 [2:59:04<26:04:42, 432.64s/it] 10%|█         | 24/240 [3:05:31<25:07:36, 418.78s/it] 10%|█         | 25/240 [3:16:32<29:21:51, 491.68s/it] 11%|█         | 26/240 [3:25:34<30:07:19, 506.73s/it] 11%|█▏        | 27/240 [3:33:53<29:50:07, 504.26s/it] 12%|█▏        | 28/240 [3:41:39<29:01:02, 492.75s/it] 12%|█▏        | 29/240 [3:49:06<28:04:59, 479.15s/it] 12%|█▎        | 30/240 [3:54:39<25:23:14, 435.21s/it]                                                       12%|█▎        | 30/240 [3:54:39<25:23:14, 435.21s/it] 13%|█▎        | 31/240 [4:00:24<23:42:36, 408.40s/it] 13%|█▎        | 32/240 [4:08:19<24:44:06, 428.11s/it] 14%|█▍        | 33/240 [4:15:40<24:51:00, 432.18s/it] 14%|█▍        | 34/240 [4:22:39<24:29:33, 428.03s/it] 15%|█▍        | 35/240 [4:29:17<23:51:57, 419.11s/it] 15%|█▌        | 36/240 [4:35:41<23:09:10, 408.58s/it] 15%|█▌        | 37/240 [4:46:34<27:10:50, 482.02s/it] 16%|█▌        | 38/240 [4:55:27<27:54:16, 497.31s/it] 16%|█▋        | 39/240 [5:03:39<27:39:54, 495.49s/it] 17%|█▋        | 40/240 [5:11:23<27:00:34, 486.17s/it]                                                       17%|█▋        | 40/240 [5:11:23<27:00:34, 486.17s/it] 17%|█▋        | 41/240 [5:18:46<26:09:59, 473.36s/it] 18%|█▊        | 42/240 [5:25:42<25:05:19, 456.16s/it] 18%|█▊        | 43/240 [5:33:15<24:53:58, 455.02s/it] 18%|█▊        | 44/240 [5:41:08<25:04:05, 460.44s/it] 19%|█▉        | 45/240 [5:48:34<24:42:02, 456.01s/it] 19%|█▉        | 46/240 [5:55:27<23:52:51, 443.15s/it] 20%|█▉        | 47/240 [6:02:07<23:03:39, 430.15s/it] 20%|██        | 48/240 [6:08:30<22:11:15, 416.02s/it] 20%|██        | 49/240 [6:17:53<24:24:44, 460.13s/it] 21%|██        | 50/240 [6:27:25<26:04:10, 493.95s/it]                                                       21%|██        | 50/240 [6:27:25<26:04:10, 493.95s/it] 21%|██▏       | 51/240 [6:35:53<26:08:19, 497.88s/it] 22%|██▏       | 52/240 [6:43:47<25:38:14, 490.93s/it] 22%|██▏       | 53/240 [6:51:18<24:52:49, 478.98s/it] 22%|██▎       | 54/240 [6:58:30<24:00:43, 464.75s/it] 23%|██▎       | 55/240 [7:13:34<30:39:44, 596.67s/it] 23%|██▎       | 56/240 [7:26:12<32:57:44, 644.91s/it] 24%|██▍       | 57/240 [7:37:08<32:57:01, 648.21s/it] 24%|██▍       | 58/240 [7:53:33<37:52:49, 749.28s/it] 25%|██▍       | 59/240 [8:09:18<40:37:32, 808.02s/it] 25%|██▌       | 60/240 [8:24:47<42:12:43, 844.24s/it]                                                       25%|██▌       | 60/240 [8:24:47<42:12:43, 844.24s/it] 25%|██▌       | 61/240 [8:43:28<46:06:54, 927.46s/it] 26%|██▌       | 62/240 [9:04:47<51:03:47, 1032.74s/it] 26%|██▋       | 63/240 [9:18:17<47:29:15, 965.85s/it]  27%|██▋       | 64/240 [9:26:12<40:01:50, 818.81s/it] 27%|██▋       | 65/240 [9:33:52<34:34:22, 711.21s/it] 28%|██▊       | 66/240 [9:41:11<30:25:08, 629.36s/it] 28%|██▊       | 67/240 [9:49:18<28:11:26, 586.63s/it] 28%|██▊       | 68/240 [9:57:23<26:34:16, 556.14s/it] 29%|██▉       | 69/240 [10:05:10<25:09:26, 529.63s/it] 29%|██▉       | 70/240 [10:14:33<25:28:54, 539.61s/it]                                                        29%|██▉       | 70/240 [10:14:33<25:28:54, 539.61s/it] 30%|██▉       | 71/240 [10:30:19<31:03:02, 661.44s/it] 30%|███       | 72/240 [10:45:51<34:39:22, 742.63s/it] 30%|███       | 73/240 [11:04:36<39:46:12, 857.32s/it] 31%|███       | 74/240 [11:25:51<45:18:07, 982.46s/it] 31%|███▏      | 75/240 [11:43:57<46:27:53, 1013.78s/it] 32%|███▏      | 76/240 [12:01:41<46:51:29, 1028.60s/it] 32%|███▏      | 77/240 [12:19:05<46:47:19, 1033.37s/it] 32%|███▎      | 78/240 [12:35:17<45:40:42, 1015.08s/it] 33%|███▎      | 79/240 [12:51:21<44:42:25, 999.66s/it]  33%|███▎      | 80/240 [13:08:50<45:05:07, 1014.42s/it]                                                         33%|███▎      | 80/240 [13:08:50<45:05:07, 1014.42s/it] 34%|███▍      | 81/240 [13:26:31<45:25:30, 1028.49s/it] 34%|███▍      | 82/240 [13:43:23<44:55:15, 1023.52s/it] 35%|███▍      | 83/240 [13:59:32<43:55:19, 1007.13s/it] 35%|███▌      | 84/240 [14:14:58<42:35:18, 982.81s/it]  35%|███▌      | 85/240 [14:33:45<44:10:34, 1026.03s/it] 36%|███▌      | 86/240 [14:55:23<47:22:47, 1107.58s/it] 36%|███▋      | 87/240 [15:14:06<47:15:55, 1112.13s/it] 37%|███▋      | 88/240 [15:31:09<45:49:57, 1085.51s/it] 37%|███▋      | 89/240 [15:47:21<44:06:18, 1051.51s/it] 38%|███▊      | 90/240 [16:03:50<43:01:50, 1032.74s/it]                                                         38%|███▊      | 90/240 [16:03:50<43:01:50, 1032.74s/it] 38%|███▊      | 91/240 [16:19:18<41:26:18, 1001.20s/it] 38%|███▊      | 92/240 [16:36:52<41:48:48, 1017.08s/it] 39%|███▉      | 93/240 [16:54:33<42:03:56, 1030.18s/it] 39%|███▉      | 94/240 [17:11:34<41:40:18, 1027.52s/it] 40%|███▉      | 95/240 [17:27:41<40:39:32, 1009.47s/it] 40%|████      | 96/240 [17:43:23<39:33:39, 989.02s/it]  40%|████      | 97/240 [17:59:52<39:17:12, 989.04s/it] 41%|████      | 98/240 [18:21:24<42:36:18, 1080.13s/it] 41%|████▏     | 99/240 [18:41:36<43:50:40, 1119.44s/it] 42%|████▏     | 100/240 [18:59:29<42:59:29, 1105.49s/it]                                                          42%|████▏     | 100/240 [18:59:29<42:59:29, 1105.49s/it] 42%|████▏     | 101/240 [19:16:34<41:45:37, 1081.56s/it] 42%|████▎     | 102/240 [19:33:25<40:38:35, 1060.26s/it] 43%|████▎     | 103/240 [19:49:33<39:17:37, 1032.53s/it] 43%|████▎     | 104/240 [20:07:30<39:31:07, 1046.08s/it] 44%|████▍     | 105/240 [20:25:22<39:30:57, 1053.76s/it] 44%|████▍     | 106/240 [20:42:27<38:54:08, 1045.14s/it] 45%|████▍     | 107/240 [20:58:45<37:52:03, 1024.99s/it] 45%|████▌     | 108/240 [21:14:29<36:41:50, 1000.84s/it] 45%|████▌     | 109/240 [21:29:55<35:36:07, 978.38s/it]  46%|████▌     | 110/240 [21:51:40<38:51:42, 1076.17s/it]                                                          46%|████▌     | 110/240 [21:51:40<38:51:42, 1076.17s/it] 46%|████▋     | 111/240 [22:12:08<40:12:06, 1121.91s/it] 47%|████▋     | 112/240 [22:29:58<39:19:42, 1106.12s/it] 47%|████▋     | 113/240 [22:47:02<38:09:25, 1081.61s/it] 48%|████▊     | 114/240 [23:03:46<37:02:10, 1058.18s/it] 48%|████▊     | 115/240 [23:19:51<35:46:38, 1030.39s/it] 48%|████▊     | 116/240 [23:38:01<36:06:15, 1048.19s/it] 49%|████▉     | 117/240 [23:55:58<36:06:29, 1056.83s/it] 49%|████▉     | 118/240 [24:12:47<35:19:53, 1042.57s/it] 50%|████▉     | 119/240 [24:19:51<28:48:06, 856.92s/it]  50%|█████     | 120/240 [24:26:38<24:04:09, 722.08s/it]                                                         50%|█████     | 120/240 [24:26:38<24:04:09, 722.08s/it] 50%|█████     | 121/240 [24:33:13<20:37:13, 623.81s/it] 51%|█████     | 122/240 [24:43:30<20:23:05, 621.91s/it] 51%|█████▏    | 123/240 [24:52:28<19:23:41, 596.76s/it] 52%|█████▏    | 124/240 [25:03:37<19:55:14, 618.23s/it] 52%|█████▏    | 125/240 [25:13:41<19:37:05, 614.13s/it] 52%|█████▎    | 126/240 [25:23:26<19:10:13, 605.38s/it] 53%|█████▎    | 127/240 [25:32:22<18:20:47, 584.49s/it] 53%|█████▎    | 128/240 [25:42:11<18:13:46, 585.95s/it] 54%|█████▍    | 129/240 [25:52:14<18:13:20, 591.00s/it] 54%|█████▍    | 130/240 [26:01:05<17:30:38, 573.08s/it]                                                         54%|█████▍    | 130/240 [26:01:05<17:30:38, 573.08s/it] 55%|█████▍    | 131/240 [26:09:53<16:56:01, 559.28s/it] 55%|█████▌    | 132/240 [26:18:23<16:20:20, 544.64s/it] 55%|█████▌    | 133/240 [26:26:15<15:32:32, 522.92s/it] 56%|█████▌    | 134/240 [26:38:07<17:03:47, 579.50s/it] 56%|█████▋    | 135/240 [26:46:59<16:29:24, 565.38s/it] 57%|█████▋    | 136/240 [26:57:48<17:03:32, 590.50s/it] 57%|█████▋    | 137/240 [27:08:15<17:12:29, 601.45s/it] 57%|█████▊    | 138/240 [27:18:26<17:07:04, 604.17s/it] 58%|█████▊    | 139/240 [27:27:57<16:40:33, 594.39s/it] 58%|█████▊    | 140/240 [27:37:33<16:21:04, 588.65s/it]                                                         58%|█████▊    | 140/240 [27:37:33<16:21:04, 588.65s/it] 59%|█████▉    | 141/240 [27:47:26<16:13:29, 589.99s/it] 59%|█████▉    | 142/240 [27:55:46<15:19:26, 562.92s/it] 60%|█████▉    | 143/240 [28:03:43<14:28:44, 537.37s/it] 60%|██████    | 144/240 [28:11:52<13:56:38, 522.90s/it] 60%|██████    | 145/240 [28:20:40<13:50:05, 524.27s/it] 61%|██████    | 146/240 [28:32:36<15:11:40, 581.92s/it] 61%|██████▏   | 147/240 [28:43:01<15:21:50, 594.73s/it] 62%|██████▏   | 148/240 [28:55:51<16:32:20, 647.18s/it] 62%|██████▏   | 149/240 [29:07:18<16:39:46, 659.19s/it] 62%|██████▎   | 150/240 [29:18:53<16:44:51, 669.90s/it]                                                         62%|██████▎   | 150/240 [29:18:53<16:44:51, 669.90s/it] 63%|██████▎   | 151/240 [29:30:00<16:32:19, 668.98s/it] 63%|██████▎   | 152/240 [29:41:16<16:24:15, 671.09s/it] 64%|██████▍   | 153/240 [29:51:55<15:59:12, 661.52s/it] 64%|██████▍   | 154/240 [30:02:07<15:26:51, 646.65s/it] 65%|██████▍   | 155/240 [30:11:54<14:50:45, 628.78s/it] 65%|██████▌   | 156/240 [30:21:38<14:21:29, 615.36s/it] 65%|██████▌   | 157/240 [30:30:47<13:43:50, 595.54s/it] 66%|██████▌   | 158/240 [30:41:30<13:53:31, 609.89s/it] 66%|██████▋   | 159/240 [30:53:37<14:30:40, 644.95s/it] 67%|██████▋   | 160/240 [31:05:46<14:53:25, 670.06s/it]                                                         67%|██████▋   | 160/240 [31:05:46<14:53:25, 670.06s/it] 67%|██████▋   | 161/240 [31:16:32<14:32:43, 662.83s/it] 68%|██████▊   | 162/240 [31:26:46<14:02:39, 648.20s/it] 68%|██████▊   | 163/240 [31:36:43<13:32:11, 632.88s/it] 68%|██████▊   | 164/240 [31:46:46<13:10:20, 623.95s/it] 69%|██████▉   | 165/240 [31:58:12<13:23:08, 642.51s/it] 69%|██████▉   | 166/240 [32:08:19<12:59:11, 631.78s/it] 70%|██████▉   | 167/240 [32:18:08<12:32:59, 618.90s/it] 70%|███████   | 168/240 [32:27:17<11:57:39, 598.05s/it] 70%|███████   | 169/240 [32:36:27<11:30:36, 583.61s/it] 71%|███████   | 170/240 [32:47:34<11:50:08, 608.70s/it]                                                         71%|███████   | 170/240 [32:47:34<11:50:08, 608.70s/it] 71%|███████▏  | 171/240 [33:00:34<12:39:06, 660.10s/it] 72%|███████▏  | 172/240 [33:12:01<12:37:04, 668.00s/it] 72%|███████▏  | 173/240 [33:23:15<12:28:14, 670.07s/it] 72%|███████▎  | 174/240 [33:33:44<12:03:17, 657.54s/it] 73%|███████▎  | 175/240 [33:42:29<11:09:23, 617.89s/it] 73%|███████▎  | 176/240 [33:50:42<10:18:57, 580.28s/it] 74%|███████▍  | 177/240 [33:58:40<9:37:04, 549.59s/it]  74%|███████▍  | 178/240 [34:06:24<9:01:32, 524.08s/it] 75%|███████▍  | 179/240 [34:13:52<8:29:27, 501.10s/it] 75%|███████▌  | 180/240 [34:21:04<8:00:28, 480.47s/it]                                                        75%|███████▌  | 180/240 [34:21:04<8:00:28, 480.47s/it] 75%|███████▌  | 181/240 [34:28:05<7:34:58, 462.68s/it] 76%|███████▌  | 182/240 [34:36:30<7:39:34, 475.42s/it] 76%|███████▋  | 183/240 [34:47:06<8:17:14, 523.42s/it] 77%|███████▋  | 184/240 [34:57:42<8:40:14, 557.39s/it] 77%|███████▋  | 185/240 [35:07:37<8:41:10, 568.56s/it] 78%|███████▊  | 186/240 [35:17:09<8:32:37, 569.59s/it] 78%|███████▊  | 187/240 [35:26:24<8:19:23, 565.34s/it] 78%|███████▊  | 188/240 [35:34:27<7:48:28, 540.56s/it] 79%|███████▉  | 189/240 [35:41:35<7:10:38, 506.63s/it] 79%|███████▉  | 190/240 [35:48:35<6:40:37, 480.75s/it]                                                        79%|███████▉  | 190/240 [35:48:35<6:40:37, 480.75s/it] 80%|███████▉  | 191/240 [35:55:41<6:19:16, 464.43s/it] 80%|████████  | 192/240 [36:02:14<5:54:14, 442.81s/it] 80%|████████  | 193/240 [36:08:53<5:36:38, 429.75s/it] 81%|████████  | 194/240 [36:16:04<5:29:41, 430.04s/it] 81%|████████▏ | 195/240 [36:26:23<6:05:13, 486.96s/it] 82%|████████▏ | 196/240 [36:38:05<6:44:14, 551.24s/it] 82%|████████▏ | 197/240 [36:47:56<6:43:41, 563.29s/it] 82%|████████▎ | 198/240 [36:56:48<6:27:36, 553.73s/it] 83%|████████▎ | 199/240 [37:05:22<6:10:26, 542.10s/it] 83%|████████▎ | 200/240 [37:13:33<5:51:04, 526.62s/it]                                                        83%|████████▎ | 200/240 [37:13:33<5:51:04, 526.62s/it]{'loss': 2.3351, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.21}
{'loss': 2.3669, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.41}
{'loss': 2.3898, 'learning_rate': 6e-06, 'epoch': 0.62}
{'loss': 2.4142, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.82}
{'loss': 2.4281, 'learning_rate': 1e-05, 'epoch': 1.03}
{'loss': 2.314, 'learning_rate': 1.2e-05, 'epoch': 1.23}
{'loss': 2.1361, 'learning_rate': 1.4e-05, 'epoch': 1.44}
{'loss': 2.0799, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.65}
{'loss': 1.9605, 'learning_rate': 1.8e-05, 'epoch': 1.85}
{'loss': 1.754, 'learning_rate': 2e-05, 'epoch': 2.06}
{'loss': 1.4591, 'learning_rate': 1.8571428571428575e-05, 'epoch': 2.26}
{'loss': 1.3227, 'learning_rate': 1.7142857142857142e-05, 'epoch': 2.47}
{'loss': 1.2646, 'learning_rate': 1.5714285714285715e-05, 'epoch': 2.68}
{'loss': 1.2359, 'learning_rate': 1.4285714285714287e-05, 'epoch': 2.88}
{'loss': 1.1966, 'learning_rate': 1.2857142857142859e-05, 'epoch': 3.09}
{'loss': 1.1635, 'learning_rate': 1.1428571428571429e-05, 'epoch': 3.29}
{'loss': 1.1324, 'learning_rate': 1e-05, 'epoch': 3.5}
{'loss': 1.1402, 'learning_rate': 8.571428571428571e-06, 'epoch': 3.7}
{'loss': 1.1356, 'learning_rate': 7.1428571428571436e-06, 'epoch': 3.91}
{'loss': 1.1168, 'learning_rate': 5.7142857142857145e-06, 'epoch': 4.12}

  0%|          | 0/250 [00:00<?, ?it/s][A
  1%|          | 2/250 [00:00<01:29,  2.77it/s][A
  1%|          | 3/250 [00:01<02:02,  2.02it/s][A
  2%|▏         | 4/250 [00:01<02:00,  2.04it/s][A
  2%|▏         | 5/250 [00:02<02:15,  1.81it/s][A
  2%|▏         | 6/250 [00:03<02:22,  1.71it/s][A
  3%|▎         | 7/250 [00:03<02:31,  1.61it/s][A
  3%|▎         | 8/250 [00:04<02:45,  1.46it/s][A
  4%|▎         | 9/250 [00:05<02:23,  1.67it/s][A
  4%|▍         | 10/250 [00:05<02:36,  1.54it/s][A
  4%|▍         | 11/250 [00:06<02:33,  1.56it/s][A
  5%|▍         | 12/250 [00:07<02:27,  1.61it/s][A
  5%|▌         | 13/250 [00:07<02:39,  1.49it/s][A
  6%|▌         | 14/250 [00:08<02:27,  1.60it/s][A
  6%|▌         | 15/250 [00:09<02:29,  1.57it/s][A
  6%|▋         | 16/250 [00:09<02:27,  1.59it/s][A
  7%|▋         | 17/250 [00:10<02:23,  1.62it/s][A
  7%|▋         | 18/250 [00:10<02:27,  1.57it/s][A
  8%|▊         | 19/250 [00:11<02:24,  1.59it/s][A
  8%|▊         | 20/250 [00:12<02:23,  1.60it/s][A
  8%|▊         | 21/250 [00:13<02:45,  1.38it/s][A
  9%|▉         | 22/250 [00:13<02:39,  1.43it/s][A
  9%|▉         | 23/250 [00:14<02:35,  1.46it/s][A
 10%|▉         | 24/250 [00:14<02:21,  1.60it/s][A
 10%|█         | 25/250 [00:15<02:17,  1.64it/s][A
 10%|█         | 26/250 [00:16<02:16,  1.64it/s][A
 11%|█         | 27/250 [00:16<02:14,  1.66it/s][A
 11%|█         | 28/250 [00:17<02:13,  1.66it/s][A
 12%|█▏        | 29/250 [00:17<02:12,  1.66it/s][A
 12%|█▏        | 30/250 [00:18<02:22,  1.54it/s][A
 12%|█▏        | 31/250 [00:19<02:21,  1.55it/s][A
 13%|█▎        | 32/250 [00:19<02:14,  1.62it/s][A
 13%|█▎        | 33/250 [00:20<02:14,  1.62it/s][A
 14%|█▎        | 34/250 [00:21<02:14,  1.60it/s][A
 14%|█▍        | 35/250 [00:21<02:14,  1.60it/s][A
 14%|█▍        | 36/250 [00:22<02:18,  1.54it/s][A
 15%|█▍        | 37/250 [00:22<01:56,  1.84it/s][A
 15%|█▌        | 38/250 [00:23<02:09,  1.64it/s][A
 16%|█▌        | 39/250 [00:24<02:10,  1.62it/s][A
 16%|█▌        | 40/250 [00:24<02:08,  1.64it/s][A
 16%|█▋        | 41/250 [00:25<02:05,  1.67it/s][A
 17%|█▋        | 42/250 [00:25<02:01,  1.71it/s][A
 17%|█▋        | 43/250 [00:26<02:10,  1.58it/s][A
 18%|█▊        | 44/250 [00:27<02:12,  1.55it/s][A
 18%|█▊        | 45/250 [00:27<02:04,  1.65it/s][A
 18%|█▊        | 46/250 [00:28<02:04,  1.64it/s][A
 19%|█▉        | 47/250 [00:29<02:06,  1.61it/s][A
 19%|█▉        | 48/250 [00:29<02:06,  1.60it/s][A
 20%|█▉        | 49/250 [00:30<02:07,  1.58it/s][A
 20%|██        | 50/250 [00:30<01:46,  1.88it/s][A
 20%|██        | 51/250 [00:31<01:54,  1.73it/s][A
 21%|██        | 52/250 [00:32<02:05,  1.58it/s][A
 21%|██        | 53/250 [00:33<02:25,  1.35it/s][A
 22%|██▏       | 54/250 [00:33<02:18,  1.42it/s][A
 22%|██▏       | 55/250 [00:34<02:07,  1.52it/s][A
 22%|██▏       | 56/250 [00:34<02:08,  1.51it/s][A
 23%|██▎       | 57/250 [00:35<02:04,  1.55it/s][A
 23%|██▎       | 58/250 [00:36<01:58,  1.61it/s][A
 24%|██▎       | 59/250 [00:36<02:12,  1.45it/s][A
 24%|██▍       | 60/250 [00:37<01:52,  1.69it/s][A
 24%|██▍       | 61/250 [00:37<01:58,  1.59it/s][A
 25%|██▍       | 62/250 [00:38<02:00,  1.56it/s][A
 25%|██▌       | 63/250 [00:39<02:00,  1.56it/s][A
 26%|██▌       | 64/250 [00:39<01:55,  1.61it/s][A
 26%|██▌       | 65/250 [00:40<01:48,  1.70it/s][A
 26%|██▋       | 66/250 [00:41<02:05,  1.47it/s][A
 27%|██▋       | 67/250 [00:41<02:04,  1.47it/s][A
 27%|██▋       | 68/250 [00:43<02:23,  1.27it/s][A
 28%|██▊       | 69/250 [00:43<02:15,  1.33it/s][A
 28%|██▊       | 70/250 [00:44<02:04,  1.45it/s][A
 28%|██▊       | 71/250 [00:44<02:03,  1.45it/s][A
 29%|██▉       | 72/250 [00:45<01:57,  1.51it/s][A
 29%|██▉       | 73/250 [00:46<01:53,  1.56it/s][A
 30%|██▉       | 74/250 [00:46<01:58,  1.48it/s][A
 30%|███       | 75/250 [00:47<01:42,  1.70it/s][A
 30%|███       | 76/250 [00:47<01:45,  1.65it/s][A
 31%|███       | 77/250 [00:48<01:48,  1.60it/s][A
 31%|███       | 78/250 [00:49<01:54,  1.51it/s][A
 32%|███▏      | 79/250 [00:49<01:53,  1.51it/s][A
 32%|███▏      | 80/250 [00:50<01:45,  1.61it/s][A
 32%|███▏      | 81/250 [00:51<01:46,  1.59it/s][A
 33%|███▎      | 82/250 [00:51<01:42,  1.64it/s][A
 33%|███▎      | 83/250 [00:52<01:39,  1.67it/s][A
 34%|███▎      | 84/250 [00:52<01:36,  1.72it/s][A
 34%|███▍      | 85/250 [00:53<01:39,  1.66it/s][A
 34%|███▍      | 86/250 [00:54<01:38,  1.66it/s][A
 35%|███▍      | 87/250 [00:54<01:34,  1.72it/s][A
 35%|███▌      | 88/250 [00:55<01:35,  1.70it/s][A
 36%|███▌      | 89/250 [00:55<01:37,  1.65it/s][A
 36%|███▌      | 90/250 [00:56<01:41,  1.57it/s][A
 36%|███▋      | 91/250 [00:56<01:29,  1.77it/s][A
 37%|███▋      | 92/250 [00:57<01:31,  1.72it/s][A
 37%|███▋      | 93/250 [00:58<01:35,  1.64it/s][A
 38%|███▊      | 94/250 [00:58<01:36,  1.62it/s][A
 38%|███▊      | 95/250 [00:59<01:44,  1.49it/s][A
 38%|███▊      | 96/250 [01:00<01:29,  1.71it/s][A
 39%|███▉      | 97/250 [01:00<01:39,  1.54it/s][A
 39%|███▉      | 98/250 [01:01<01:38,  1.54it/s][A
 40%|███▉      | 99/250 [01:02<01:35,  1.59it/s][A
 40%|████      | 100/250 [01:02<01:34,  1.59it/s][A
 40%|████      | 101/250 [01:03<01:25,  1.73it/s][A
 41%|████      | 102/250 [01:03<01:32,  1.60it/s][A
 41%|████      | 103/250 [01:04<01:33,  1.57it/s][A
 42%|████▏     | 104/250 [01:05<01:37,  1.50it/s][A
 42%|████▏     | 105/250 [01:06<01:42,  1.42it/s][A
 42%|████▏     | 106/250 [01:06<01:36,  1.49it/s][A
 43%|████▎     | 107/250 [01:07<01:53,  1.26it/s][A
 43%|████▎     | 108/250 [01:08<01:41,  1.40it/s][A
 44%|████▎     | 109/250 [01:08<01:37,  1.45it/s][A
 44%|████▍     | 110/250 [01:09<01:39,  1.41it/s][A
 44%|████▍     | 111/250 [01:10<01:38,  1.41it/s][A
 45%|████▍     | 112/250 [01:11<01:40,  1.38it/s][A
 45%|████▌     | 113/250 [01:11<01:40,  1.36it/s][A
 46%|████▌     | 114/250 [01:12<01:40,  1.35it/s][A
 46%|████▌     | 115/250 [01:13<01:37,  1.39it/s][A
 46%|████▋     | 116/250 [01:13<01:33,  1.44it/s][A
 47%|████▋     | 117/250 [01:14<01:25,  1.56it/s][A
 47%|████▋     | 118/250 [01:15<01:23,  1.59it/s][A
 48%|████▊     | 119/250 [01:15<01:23,  1.57it/s][A
 48%|████▊     | 120/250 [01:16<01:20,  1.61it/s][A
 48%|████▊     | 121/250 [01:17<01:22,  1.56it/s][A
 49%|████▉     | 122/250 [01:17<01:15,  1.69it/s][A
 49%|████▉     | 123/250 [01:18<01:15,  1.69it/s][A
 50%|████▉     | 124/250 [01:18<01:19,  1.59it/s][A
 50%|█████     | 125/250 [01:19<01:17,  1.61it/s][A
 50%|█████     | 126/250 [01:20<01:19,  1.55it/s][A
 51%|█████     | 127/250 [01:20<01:11,  1.71it/s][A
 51%|█████     | 128/250 [01:21<01:18,  1.56it/s][A
 52%|█████▏    | 129/250 [01:21<01:18,  1.54it/s][A
 52%|█████▏    | 130/250 [01:22<01:17,  1.56it/s][A
 52%|█████▏    | 131/250 [01:23<01:18,  1.51it/s][A
 53%|█████▎    | 132/250 [01:23<01:14,  1.57it/s][A
 53%|█████▎    | 133/250 [01:24<01:14,  1.56it/s][A
 54%|█████▎    | 134/250 [01:25<01:12,  1.59it/s][A
 54%|█████▍    | 135/250 [01:25<01:14,  1.54it/s][A
 54%|█████▍    | 136/250 [01:26<01:11,  1.59it/s][A
 55%|█████▍    | 137/250 [01:26<01:07,  1.67it/s][A
 55%|█████▌    | 138/250 [01:27<01:05,  1.70it/s][A
 56%|█████▌    | 139/250 [01:28<01:09,  1.60it/s][A
 56%|█████▌    | 140/250 [01:29<01:15,  1.46it/s][A
 56%|█████▋    | 141/250 [01:29<01:18,  1.38it/s][A
 57%|█████▋    | 142/250 [01:30<01:20,  1.35it/s][A
 57%|█████▋    | 143/250 [01:31<01:17,  1.38it/s][A
 58%|█████▊    | 144/250 [01:32<01:15,  1.40it/s][A
 58%|█████▊    | 145/250 [01:32<01:12,  1.45it/s][A
 58%|█████▊    | 146/250 [01:33<01:12,  1.44it/s][A
 59%|█████▉    | 147/250 [01:34<01:09,  1.47it/s][A
 59%|█████▉    | 148/250 [01:34<01:01,  1.66it/s][A
 60%|█████▉    | 149/250 [01:35<01:06,  1.53it/s][A
 60%|██████    | 150/250 [01:35<01:03,  1.58it/s][A
 60%|██████    | 151/250 [01:36<01:13,  1.34it/s][A
 61%|██████    | 152/250 [01:37<01:09,  1.41it/s][A
 61%|██████    | 153/250 [01:38<01:15,  1.28it/s][A
 62%|██████▏   | 154/250 [01:39<01:13,  1.31it/s][A
 62%|██████▏   | 155/250 [01:39<01:10,  1.34it/s][A
 62%|██████▏   | 156/250 [01:40<01:07,  1.39it/s][A
 63%|██████▎   | 157/250 [01:40<00:56,  1.64it/s][A
 63%|██████▎   | 158/250 [01:41<00:55,  1.66it/s][A
 64%|██████▎   | 159/250 [01:42<00:56,  1.62it/s][A
 64%|██████▍   | 160/250 [01:42<00:50,  1.78it/s][A
 64%|██████▍   | 161/250 [01:43<00:51,  1.74it/s][A
 65%|██████▍   | 162/250 [01:43<00:51,  1.70it/s][A
 65%|██████▌   | 163/250 [01:44<00:50,  1.74it/s][A
 66%|██████▌   | 164/250 [01:45<00:54,  1.58it/s][A
 66%|██████▌   | 165/250 [01:45<00:56,  1.50it/s][A
 66%|██████▋   | 166/250 [01:46<00:53,  1.56it/s][A
 67%|██████▋   | 167/250 [01:46<00:53,  1.56it/s][A
 67%|██████▋   | 168/250 [01:48<01:02,  1.31it/s][A
 68%|██████▊   | 169/250 [01:48<01:00,  1.33it/s][A
 68%|██████▊   | 170/250 [01:49<00:56,  1.41it/s][A
 68%|██████▊   | 171/250 [01:50<00:55,  1.43it/s][A
 69%|██████▉   | 172/250 [01:50<00:50,  1.55it/s][A
 69%|██████▉   | 173/250 [01:51<00:49,  1.57it/s][A
 70%|██████▉   | 174/250 [01:52<00:54,  1.39it/s][A
 70%|███████   | 175/250 [01:52<00:51,  1.47it/s][A
 70%|███████   | 176/250 [01:53<00:50,  1.46it/s][A
 71%|███████   | 177/250 [01:53<00:42,  1.74it/s][A
 71%|███████   | 178/250 [01:54<00:40,  1.76it/s][A
 72%|███████▏  | 179/250 [01:54<00:42,  1.68it/s][A
 72%|███████▏  | 180/250 [01:55<00:46,  1.50it/s][A
 72%|███████▏  | 181/250 [01:56<00:46,  1.47it/s][A
 73%|███████▎  | 182/250 [01:57<00:47,  1.45it/s][A
 73%|███████▎  | 183/250 [01:57<00:46,  1.45it/s][A
 74%|███████▎  | 184/250 [01:58<00:40,  1.62it/s][A
 74%|███████▍  | 185/250 [01:58<00:39,  1.65it/s][A
 74%|███████▍  | 186/250 [01:59<00:38,  1.66it/s][A
 75%|███████▍  | 187/250 [01:59<00:34,  1.85it/s][A
 75%|███████▌  | 188/250 [02:00<00:40,  1.54it/s][A
 76%|███████▌  | 189/250 [02:01<00:40,  1.51it/s][A
 76%|███████▌  | 190/250 [02:02<00:41,  1.44it/s][A
 76%|███████▋  | 191/250 [02:02<00:41,  1.44it/s][A
 77%|███████▋  | 192/250 [02:03<00:41,  1.39it/s][A
 77%|███████▋  | 193/250 [02:04<00:39,  1.45it/s][A
 78%|███████▊  | 194/250 [02:04<00:36,  1.52it/s][A
 78%|███████▊  | 195/250 [02:05<00:34,  1.58it/s][A
 78%|███████▊  | 196/250 [02:06<00:34,  1.55it/s][A
 79%|███████▉  | 197/250 [02:06<00:34,  1.51it/s][A
 79%|███████▉  | 198/250 [02:07<00:35,  1.44it/s][A
 80%|███████▉  | 199/250 [02:08<00:33,  1.50it/s][A
 80%|████████  | 200/250 [02:08<00:31,  1.57it/s][A
 80%|████████  | 201/250 [02:09<00:30,  1.60it/s][A
 81%|████████  | 202/250 [02:10<00:32,  1.46it/s][A
 81%|████████  | 203/250 [02:10<00:32,  1.46it/s][A
 82%|████████▏ | 204/250 [02:11<00:30,  1.51it/s][A
 82%|████████▏ | 205/250 [02:12<00:27,  1.62it/s][A
 82%|████████▏ | 206/250 [02:12<00:26,  1.63it/s][A
 83%|████████▎ | 207/250 [02:13<00:26,  1.63it/s][A
 83%|████████▎ | 208/250 [02:14<00:28,  1.50it/s][A
 84%|████████▎ | 209/250 [02:14<00:24,  1.66it/s][A
 84%|████████▍ | 210/250 [02:15<00:23,  1.67it/s][A
 84%|████████▍ | 211/250 [02:15<00:24,  1.62it/s][A
 85%|████████▍ | 212/250 [02:16<00:25,  1.51it/s][A
 85%|████████▌ | 213/250 [02:17<00:25,  1.44it/s][A
 86%|████████▌ | 214/250 [02:17<00:23,  1.51it/s][A
 86%|████████▌ | 215/250 [02:18<00:24,  1.43it/s][A
 86%|████████▋ | 216/250 [02:19<00:22,  1.54it/s][A
 87%|████████▋ | 217/250 [02:19<00:20,  1.57it/s][A
 87%|████████▋ | 218/250 [02:20<00:20,  1.56it/s][A
 88%|████████▊ | 219/250 [02:21<00:20,  1.53it/s][A
 88%|████████▊ | 220/250 [02:21<00:19,  1.51it/s][A
 88%|████████▊ | 221/250 [02:22<00:16,  1.72it/s][A
 89%|████████▉ | 222/250 [02:23<00:18,  1.48it/s][A
 89%|████████▉ | 223/250 [02:23<00:18,  1.49it/s][A
 90%|████████▉ | 224/250 [02:24<00:17,  1.51it/s][A
 90%|█████████ | 225/250 [02:25<00:16,  1.54it/s][A
 90%|█████████ | 226/250 [02:25<00:14,  1.71it/s][A
 91%|█████████ | 227/250 [02:26<00:13,  1.69it/s][A
 91%|█████████ | 228/250 [02:26<00:13,  1.63it/s][A
 92%|█████████▏| 229/250 [02:27<00:12,  1.63it/s][A
 92%|█████████▏| 230/250 [02:28<00:12,  1.58it/s][A
 92%|█████████▏| 231/250 [02:28<00:10,  1.78it/s][A
 93%|█████████▎| 232/250 [02:29<00:10,  1.76it/s][A
 93%|█████████▎| 233/250 [02:29<00:10,  1.66it/s][A
 94%|█████████▎| 234/250 [02:30<00:09,  1.62it/s][A
 94%|█████████▍| 235/250 [02:30<00:09,  1.66it/s][A
 94%|█████████▍| 236/250 [02:31<00:07,  1.78it/s][A
 95%|█████████▍| 237/250 [02:32<00:07,  1.67it/s][A
 95%|█████████▌| 238/250 [02:32<00:07,  1.59it/s][A
 96%|█████████▌| 239/250 [02:33<00:06,  1.59it/s][A
 96%|█████████▌| 240/250 [02:34<00:06,  1.53it/s][A
 96%|█████████▋| 241/250 [02:34<00:04,  1.81it/s][A
 97%|█████████▋| 242/250 [02:35<00:04,  1.71it/s][A
 97%|█████████▋| 243/250 [02:35<00:04,  1.66it/s][A
 98%|█████████▊| 244/250 [02:36<00:03,  1.73it/s][A
 98%|█████████▊| 245/250 [02:36<00:02,  1.72it/s][A
 98%|█████████▊| 246/250 [02:37<00:02,  1.70it/s][A
 99%|█████████▉| 247/250 [02:38<00:01,  1.67it/s][A
 99%|█████████▉| 248/250 [02:39<00:01,  1.40it/s][A
100%|█████████▉| 249/250 [02:39<00:00,  1.44it/s][A
100%|██████████| 250/250 [02:40<00:00,  1.41it/s][A                                                       
                                                 [A 83%|████████▎ | 200/240 [37:16:14<5:51:04, 526.62s/it]
100%|██████████| 250/250 [02:40<00:00,  1.41it/s][A
                                                 [A/home/tricorder/yang/anaconda3/envs/llama_alpaca_lora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 84%|████████▍ | 201/240 [37:21:34<5:33:22, 512.88s/it] 84%|████████▍ | 202/240 [37:27:11<4:51:31, 460.29s/it] 85%|████████▍ | 203/240 [37:33:02<4:23:36, 427.47s/it] 85%|████████▌ | 204/240 [37:39:19<4:07:17, 412.16s/it] 85%|████████▌ | 205/240 [37:44:11<3:39:21, 376.06s/it] 86%|████████▌ | 206/240 [37:49:06<3:19:24, 351.89s/it] 86%|████████▋ | 207/240 [37:59:04<3:54:13, 425.86s/it] 87%|████████▋ | 208/240 [38:06:56<3:54:29, 439.68s/it] 87%|████████▋ | 209/240 [38:12:55<3:34:37, 415.40s/it] 88%|████████▊ | 210/240 [38:18:28<3:15:22, 390.77s/it]                                                        88%|████████▊ | 210/240 [38:18:28<3:15:22, 390.77s/it] 88%|████████▊ | 211/240 [38:23:50<2:58:49, 369.97s/it] 88%|████████▊ | 212/240 [38:29:16<2:46:28, 356.75s/it] 89%|████████▉ | 213/240 [38:34:55<2:38:06, 351.35s/it] 89%|████████▉ | 214/240 [38:39:54<2:25:26, 335.64s/it] 90%|████████▉ | 215/240 [38:45:26<2:19:26, 334.64s/it] 90%|█████████ | 216/240 [38:50:40<2:11:22, 328.44s/it] 90%|█████████ | 217/240 [38:55:23<2:00:40, 314.80s/it] 91%|█████████ | 218/240 [39:00:17<1:53:10, 308.65s/it] 91%|█████████▏| 219/240 [39:09:52<2:16:01, 388.62s/it] 92%|█████████▏| 220/240 [39:20:09<2:32:19, 456.96s/it]                                                        92%|█████████▏| 220/240 [39:20:09<2:32:19, 456.96s/it] 92%|█████████▏| 221/240 [39:28:56<2:31:23, 478.07s/it] 92%|█████████▎| 222/240 [39:35:46<2:17:17, 457.66s/it] 93%|█████████▎| 223/240 [39:41:19<1:59:06, 420.37s/it] 93%|█████████▎| 224/240 [39:47:50<1:49:40, 411.30s/it] 94%|█████████▍| 225/240 [39:53:31<1:37:35, 390.37s/it] 94%|█████████▍| 226/240 [39:59:36<1:29:18, 382.72s/it] 95%|█████████▍| 227/240 [40:04:54<1:18:42, 363.27s/it] 95%|█████████▌| 228/240 [40:09:42<1:08:07, 340.65s/it] 95%|█████████▌| 229/240 [40:14:50<1:00:40, 330.93s/it] 96%|█████████▌| 230/240 [40:20:08<54:31, 327.20s/it]                                                        96%|█████████▌| 230/240 [40:20:08<54:31, 327.20s/it] 96%|█████████▋| 231/240 [40:28:36<57:11, 381.28s/it] 97%|█████████▋| 232/240 [40:39:13<1:01:04, 458.12s/it] 97%|█████████▋| 233/240 [40:48:00<55:51, 478.79s/it]   98%|█████████▊| 234/240 [40:54:38<45:27, 454.56s/it] 98%|█████████▊| 235/240 [40:59:40<34:02, 408.59s/it] 98%|█████████▊| 236/240 [41:05:54<26:33, 398.31s/it] 99%|█████████▉| 237/240 [41:11:42<19:09, 383.17s/it] 99%|█████████▉| 238/240 [41:16:46<11:58, 359.36s/it]100%|█████████▉| 239/240 [41:21:54<05:44, 344.18s/it]100%|██████████| 240/240 [41:27:07<00:00, 334.59s/it]                                                     100%|██████████| 240/240 [41:27:07<00:00, 334.59s/it]There were missing keys in the checkpoint model loaded: ['base_model.model.model.embed_tokens.weight', 'base_model.model.model.layers.0.self_attn.q_proj.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.weight', 'base_model.model.model.layers.0.self_attn.v_proj.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.weight', 'base_model.model.model.layers.0.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.0.mlp.gate_proj.weight', 'base_model.model.model.layers.0.mlp.down_proj.weight', 'base_model.model.model.layers.0.mlp.up_proj.weight', 'base_model.model.model.layers.0.input_layernorm.weight', 'base_model.model.model.layers.0.post_attention_layernorm.weight', 'base_model.model.model.layers.1.self_attn.q_proj.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.weight', 'base_model.model.model.layers.1.self_attn.v_proj.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.weight', 'base_model.model.model.layers.1.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.1.mlp.gate_proj.weight', 'base_model.model.model.layers.1.mlp.down_proj.weight', 'base_model.model.model.layers.1.mlp.up_proj.weight', 'base_model.model.model.layers.1.input_layernorm.weight', 'base_model.model.model.layers.1.post_attention_layernorm.weight', 'base_model.model.model.layers.2.self_attn.q_proj.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.weight', 'base_model.model.model.layers.2.self_attn.v_proj.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.weight', 'base_model.model.model.layers.2.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.2.mlp.gate_proj.weight', 'base_model.model.model.layers.2.mlp.down_proj.weight', 'base_model.model.model.layers.2.mlp.up_proj.weight', 'base_model.model.model.layers.2.input_layernorm.weight', 'base_model.model.model.layers.2.post_attention_layernorm.weight', 'base_model.model.model.layers.3.self_attn.q_proj.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.weight', 'base_model.model.model.layers.3.self_attn.v_proj.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.weight', 'base_model.model.model.layers.3.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.3.mlp.gate_proj.weight', 'base_model.model.model.layers.3.mlp.down_proj.weight', 'base_model.model.model.layers.3.mlp.up_proj.weight', 'base_model.model.model.layers.3.input_layernorm.weight', 'base_model.model.model.layers.3.post_attention_layernorm.weight', 'base_model.model.model.layers.4.self_attn.q_proj.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.weight', 'base_model.model.model.layers.4.self_attn.v_proj.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.weight', 'base_model.model.model.layers.4.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.4.mlp.gate_proj.weight', 'base_model.model.model.layers.4.mlp.down_proj.weight', 'base_model.model.model.layers.4.mlp.up_proj.weight', 'base_model.model.model.layers.4.input_layernorm.weight', 'base_model.model.model.layers.4.post_attention_layernorm.weight', 'base_model.model.model.layers.5.self_attn.q_proj.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.weight', 'base_model.model.model.layers.5.self_attn.v_proj.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.weight', 'base_model.model.model.layers.5.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.5.mlp.gate_proj.weight', 'base_model.model.model.layers.5.mlp.down_proj.weight', 'base_model.model.model.layers.5.mlp.up_proj.weight', 'base_model.model.model.layers.5.input_layernorm.weight', 'base_model.model.model.layers.5.post_attention_layernorm.weight', 'base_model.model.model.layers.6.self_attn.q_proj.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.weight', 'base_model.model.model.layers.6.self_attn.v_proj.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.weight', 'base_model.model.model.layers.6.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.6.mlp.gate_proj.weight', 'base_model.model.model.layers.6.mlp.down_proj.weight', 'base_model.model.model.layers.6.mlp.up_proj.weight', 'base_model.model.model.layers.6.input_layernorm.weight', 'base_model.model.model.layers.6.post_attention_layernorm.weight', 'base_model.model.model.layers.7.self_attn.q_proj.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.weight', 'base_model.model.model.layers.7.self_attn.v_proj.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.weight', 'base_model.model.model.layers.7.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.7.mlp.gate_proj.weight', 'base_model.model.model.layers.7.mlp.down_proj.weight', 'base_model.model.model.layers.7.mlp.up_proj.weight', 'base_model.model.model.layers.7.input_layernorm.weight', 'base_model.model.model.layers.7.post_attention_layernorm.weight', 'base_model.model.model.layers.8.self_attn.q_proj.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.weight', 'base_model.model.model.layers.8.self_attn.v_proj.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.weight', 'base_model.model.model.layers.8.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.8.mlp.gate_proj.weight', 'base_model.model.model.layers.8.mlp.down_proj.weight', 'base_model.model.model.layers.8.mlp.up_proj.weight', 'base_model.model.model.layers.8.input_layernorm.weight', 'base_model.model.model.layers.8.post_attention_layernorm.weight', 'base_model.model.model.layers.9.self_attn.q_proj.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.weight', 'base_model.model.model.layers.9.self_attn.v_proj.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.weight', 'base_model.model.model.layers.9.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.9.mlp.gate_proj.weight', 'base_model.model.model.layers.9.mlp.down_proj.weight', 'base_model.model.model.layers.9.mlp.up_proj.weight', 'base_model.model.model.layers.9.input_layernorm.weight', 'base_model.model.model.layers.9.post_attention_layernorm.weight', 'base_model.model.model.layers.10.self_attn.q_proj.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.weight', 'base_model.model.model.layers.10.self_attn.v_proj.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.weight', 'base_model.model.model.layers.10.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.10.mlp.gate_proj.weight', 'base_model.model.model.layers.10.mlp.down_proj.weight', 'base_model.model.model.layers.10.mlp.up_proj.weight', 'base_model.model.model.layers.10.input_layernorm.weight', 'base_model.model.model.layers.10.post_attention_layernorm.weight', 'base_model.model.model.layers.11.self_attn.q_proj.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.weight', 'base_model.model.model.layers.11.self_attn.v_proj.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.weight', 'base_model.model.model.layers.11.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.11.mlp.gate_proj.weight', 'base_model.model.model.layers.11.mlp.down_proj.weight', 'base_model.model.model.layers.11.mlp.up_proj.weight', 'base_model.model.model.layers.11.input_layernorm.weight', 'base_model.model.model.layers.11.post_attention_layernorm.weight', 'base_model.model.model.layers.12.self_attn.q_proj.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.weight', 'base_model.model.model.layers.12.self_attn.v_proj.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.weight', 'base_model.model.model.layers.12.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.12.mlp.gate_proj.weight', 'base_model.model.model.layers.12.mlp.down_proj.weight', 'base_model.model.model.layers.12.mlp.up_proj.weight', 'base_model.model.model.layers.12.input_layernorm.weight', 'base_model.model.model.layers.12.post_attention_layernorm.weight', 'base_model.model.model.layers.13.self_attn.q_proj.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.weight', 'base_model.model.model.layers.13.self_attn.v_proj.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.weight', 'base_model.model.model.layers.13.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.13.mlp.gate_proj.weight', 'base_model.model.model.layers.13.mlp.down_proj.weight', 'base_model.model.model.layers.13.mlp.up_proj.weight', 'base_model.model.model.layers.13.input_layernorm.weight', 'base_model.model.model.layers.13.post_attention_layernorm.weight', 'base_model.model.model.layers.14.self_attn.q_proj.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.weight', 'base_model.model.model.layers.14.self_attn.v_proj.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.weight', 'base_model.model.model.layers.14.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.14.mlp.gate_proj.weight', 'base_model.model.model.layers.14.mlp.down_proj.weight', 'base_model.model.model.layers.14.mlp.up_proj.weight', 'base_model.model.model.layers.14.input_layernorm.weight', 'base_model.model.model.layers.14.post_attention_layernorm.weight', 'base_model.model.model.layers.15.self_attn.q_proj.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.weight', 'base_model.model.model.layers.15.self_attn.v_proj.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.weight', 'base_model.model.model.layers.15.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.15.mlp.gate_proj.weight', 'base_model.model.model.layers.15.mlp.down_proj.weight', 'base_model.model.model.layers.15.mlp.up_proj.weight', 'base_model.model.model.layers.15.input_layernorm.weight', 'base_model.model.model.layers.15.post_attention_layernorm.weight', 'base_model.model.model.layers.16.self_attn.q_proj.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.weight', 'base_model.model.model.layers.16.self_attn.v_proj.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.weight', 'base_model.model.model.layers.16.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.16.mlp.gate_proj.weight', 'base_model.model.model.layers.16.mlp.down_proj.weight', 'base_model.model.model.layers.16.mlp.up_proj.weight', 'base_model.model.model.layers.16.input_layernorm.weight', 'base_model.model.model.layers.16.post_attention_layernorm.weight', 'base_model.model.model.layers.17.self_attn.q_proj.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.weight', 'base_model.model.model.layers.17.self_attn.v_proj.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.weight', 'base_model.model.model.layers.17.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.17.mlp.gate_proj.weight', 'base_model.model.model.layers.17.mlp.down_proj.weight', 'base_model.model.model.layers.17.mlp.up_proj.weight', 'base_model.model.model.layers.17.input_layernorm.weight', 'base_model.model.model.layers.17.post_attention_layernorm.weight', 'base_model.model.model.layers.18.self_attn.q_proj.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.weight', 'base_model.model.model.layers.18.self_attn.v_proj.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.weight', 'base_model.model.model.layers.18.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.18.mlp.gate_proj.weight', 'base_model.model.model.layers.18.mlp.down_proj.weight', 'base_model.model.model.layers.18.mlp.up_proj.weight', 'base_model.model.model.layers.18.input_layernorm.weight', 'base_model.model.model.layers.18.post_attention_layernorm.weight', 'base_model.model.model.layers.19.self_attn.q_proj.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.weight', 'base_model.model.model.layers.19.self_attn.v_proj.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.weight', 'base_model.model.model.layers.19.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.19.mlp.gate_proj.weight', 'base_model.model.model.layers.19.mlp.down_proj.weight', 'base_model.model.model.layers.19.mlp.up_proj.weight', 'base_model.model.model.layers.19.input_layernorm.weight', 'base_model.model.model.layers.19.post_attention_layernorm.weight', 'base_model.model.model.layers.20.self_attn.q_proj.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.weight', 'base_model.model.model.layers.20.self_attn.v_proj.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.weight', 'base_model.model.model.layers.20.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.20.mlp.gate_proj.weight', 'base_model.model.model.layers.20.mlp.down_proj.weight', 'base_model.model.model.layers.20.mlp.up_proj.weight', 'base_model.model.model.layers.20.input_layernorm.weight', 'base_model.model.model.layers.20.post_attention_layernorm.weight', 'base_model.model.model.layers.21.self_attn.q_proj.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.weight', 'base_model.model.model.layers.21.self_attn.v_proj.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.weight', 'base_model.model.model.layers.21.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.21.mlp.gate_proj.weight', 'base_model.model.model.layers.21.mlp.down_proj.weight', 'base_model.model.model.layers.21.mlp.up_proj.weight', 'base_model.model.model.layers.21.input_layernorm.weight', 'base_model.model.model.layers.21.post_attention_layernorm.weight', 'base_model.model.model.layers.22.self_attn.q_proj.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.weight', 'base_model.model.model.layers.22.self_attn.v_proj.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.weight', 'base_model.model.model.layers.22.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.22.mlp.gate_proj.weight', 'base_model.model.model.layers.22.mlp.down_proj.weight', 'base_model.model.model.layers.22.mlp.up_proj.weight', 'base_model.model.model.layers.22.input_layernorm.weight', 'base_model.model.model.layers.22.post_attention_layernorm.weight', 'base_model.model.model.layers.23.self_attn.q_proj.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.weight', 'base_model.model.model.layers.23.self_attn.v_proj.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.weight', 'base_model.model.model.layers.23.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.23.mlp.gate_proj.weight', 'base_model.model.model.layers.23.mlp.down_proj.weight', 'base_model.model.model.layers.23.mlp.up_proj.weight', 'base_model.model.model.layers.23.input_layernorm.weight', 'base_model.model.model.layers.23.post_attention_layernorm.weight', 'base_model.model.model.layers.24.self_attn.q_proj.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.weight', 'base_model.model.model.layers.24.self_attn.v_proj.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.weight', 'base_model.model.model.layers.24.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.24.mlp.gate_proj.weight', 'base_model.model.model.layers.24.mlp.down_proj.weight', 'base_model.model.model.layers.24.mlp.up_proj.weight', 'base_model.model.model.layers.24.input_layernorm.weight', 'base_model.model.model.layers.24.post_attention_layernorm.weight', 'base_model.model.model.layers.25.self_attn.q_proj.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.weight', 'base_model.model.model.layers.25.self_attn.v_proj.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.weight', 'base_model.model.model.layers.25.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.25.mlp.gate_proj.weight', 'base_model.model.model.layers.25.mlp.down_proj.weight', 'base_model.model.model.layers.25.mlp.up_proj.weight', 'base_model.model.model.layers.25.input_layernorm.weight', 'base_model.model.model.layers.25.post_attention_layernorm.weight', 'base_model.model.model.layers.26.self_attn.q_proj.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.weight', 'base_model.model.model.layers.26.self_attn.v_proj.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.o_proj.weight', 'base_model.model.model.layers.26.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.26.mlp.gate_proj.weight', 'base_model.model.model.layers.26.mlp.down_proj.weight', 'base_model.model.model.layers.26.mlp.up_proj.weight', 'base_model.model.model.layers.26.input_layernorm.weight', 'base_model.model.model.layers.26.post_attention_layernorm.weight', 'base_model.model.model.layers.27.self_attn.q_proj.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.weight', 'base_model.model.model.layers.27.self_attn.v_proj.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.o_proj.weight', 'base_model.model.model.layers.27.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.27.mlp.gate_proj.weight', 'base_model.model.model.layers.27.mlp.down_proj.weight', 'base_model.model.model.layers.27.mlp.up_proj.weight', 'base_model.model.model.layers.27.input_layernorm.weight', 'base_model.model.model.layers.27.post_attention_layernorm.weight', 'base_model.model.model.layers.28.self_attn.q_proj.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.weight', 'base_model.model.model.layers.28.self_attn.v_proj.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.o_proj.weight', 'base_model.model.model.layers.28.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.28.mlp.gate_proj.weight', 'base_model.model.model.layers.28.mlp.down_proj.weight', 'base_model.model.model.layers.28.mlp.up_proj.weight', 'base_model.model.model.layers.28.input_layernorm.weight', 'base_model.model.model.layers.28.post_attention_layernorm.weight', 'base_model.model.model.layers.29.self_attn.q_proj.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.weight', 'base_model.model.model.layers.29.self_attn.v_proj.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.o_proj.weight', 'base_model.model.model.layers.29.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.29.mlp.gate_proj.weight', 'base_model.model.model.layers.29.mlp.down_proj.weight', 'base_model.model.model.layers.29.mlp.up_proj.weight', 'base_model.model.model.layers.29.input_layernorm.weight', 'base_model.model.model.layers.29.post_attention_layernorm.weight', 'base_model.model.model.layers.30.self_attn.q_proj.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.weight', 'base_model.model.model.layers.30.self_attn.v_proj.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.o_proj.weight', 'base_model.model.model.layers.30.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.30.mlp.gate_proj.weight', 'base_model.model.model.layers.30.mlp.down_proj.weight', 'base_model.model.model.layers.30.mlp.up_proj.weight', 'base_model.model.model.layers.30.input_layernorm.weight', 'base_model.model.model.layers.30.post_attention_layernorm.weight', 'base_model.model.model.layers.31.self_attn.q_proj.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.weight', 'base_model.model.model.layers.31.self_attn.v_proj.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.o_proj.weight', 'base_model.model.model.layers.31.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.31.mlp.gate_proj.weight', 'base_model.model.model.layers.31.mlp.down_proj.weight', 'base_model.model.model.layers.31.mlp.up_proj.weight', 'base_model.model.model.layers.31.input_layernorm.weight', 'base_model.model.model.layers.31.post_attention_layernorm.weight', 'base_model.model.model.norm.weight', 'base_model.model.lm_head.weight'].
There were unexpected keys in the checkpoint model loaded: ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight'].
                                                     100%|██████████| 240/240 [41:27:07<00:00, 334.59s/it]100%|██████████| 240/240 [41:27:07<00:00, 621.78s/it]
ERROR: Could not consume arg:  
Usage: finetune.py ' ' ' ' --base_model /home/tricorder/test/gxc/decapoda-research/llama-7b-hf ' ' ' ' --data_path ../data/alpaca_data_cleaned_archive.json ' ' ' ' --output_dir ../lora_alpaca_output_free/cleaned/ ' ' ' ' --batch_size 1024 ' ' ' ' --micro_batch_size 4 ' ' ' ' --num_epochs 5 ' ' ' ' --learning_rate 2e-5 ' ' ' ' --cutoff_len 512 ' ' ' ' --val_set_size 2000 ' ' ' ' --lora_r

For detailed information on this command, run:
  finetune.py ' ' ' ' --base_model /home/tricorder/test/gxc/decapoda-research/llama-7b-hf ' ' ' ' --data_path ../data/alpaca_data_cleaned_archive.json ' ' ' ' --output_dir ../lora_alpaca_output_free/cleaned/ ' ' ' ' --batch_size 1024 ' ' ' ' --micro_batch_size 4 ' ' ' ' --num_epochs 5 ' ' ' ' --learning_rate 2e-5 ' ' ' ' --cutoff_len 512 ' ' ' ' --val_set_size 2000 ' ' ' ' --lora_r --help
{'eval_loss': 1.140302300453186, 'eval_runtime': 161.05, 'eval_samples_per_second': 12.419, 'eval_steps_per_second': 1.552, 'epoch': 4.12}
{'loss': 1.0914, 'learning_rate': 4.2857142857142855e-06, 'epoch': 4.32}
{'loss': 1.0811, 'learning_rate': 2.8571428571428573e-06, 'epoch': 4.53}
{'loss': 1.0796, 'learning_rate': 1.4285714285714286e-06, 'epoch': 4.73}
{'loss': 1.1104, 'learning_rate': 0.0, 'epoch': 4.94}
{'train_runtime': 149232.5965, 'train_samples_per_second': 1.667, 'train_steps_per_second': 0.002, 'train_loss': 1.6128527442614238, 'epoch': 4.94}

 If there's a warning about missing keys above, please disregard :)
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: \ 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: | 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: / 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: - 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: \ 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: | 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: / 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: - 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: \ 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                      eval/loss ▁
wandb:                   eval/runtime ▁
wandb:        eval/samples_per_second ▁
wandb:          eval/steps_per_second ▁
wandb:                    train/epoch ▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇███
wandb:              train/global_step ▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇███
wandb:            train/learning_rate ▂▂▃▄▅▅▆▇▇██▇▇▆▆▅▅▄▄▃▂▂▂▁
wandb:                     train/loss █████▇▆▆▆▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                      eval/loss 1.1403
wandb:                   eval/runtime 161.05
wandb:        eval/samples_per_second 12.419
wandb:          eval/steps_per_second 1.552
wandb:                    train/epoch 4.94
wandb:              train/global_step 240
wandb:            train/learning_rate 0.0
wandb:                     train/loss 1.1104
wandb:               train/total_flos 1.2848589869442662e+18
wandb:               train/train_loss 1.61285
wandb:            train/train_runtime 149232.5965
wandb: train/train_samples_per_second 1.667
wandb:   train/train_steps_per_second 0.002
wandb: 
wandb: 🚀 View run   at: https://wandb.ai/gaoxiaoce0428/llama_test_project/runs/xce58c9m
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230508_022333-xce58c9m/logs
